[
  {
    "user": "HumanAIGC-Engineering",
    "name": "OpenAvatarChat",
    "readme": "<h1 style='text-align: center; margin-bottom: 1rem'> Open Avatar Chat </h1>\n\n<div align=\"center\">\n<strong>中文|<a href=\"./readme_en.md\">English</a></strong>\n</div>\n<h3 style='text-align: center'>\n模块化的交互数字人对话实现，能够在单台PC上运行完整功能。\n</h3>\n<div style=\"display: flex; flex-direction: row; justify-content: center\">\n<a href=\"https://github.com/HumanAIGC-Engineering/OpenAvatarChat\" target=\"_blank\"><img alt=\"Static Badge\" style=\"display: block; padding-right: 5px; height: 20px;\" src=\"https://img.shields.io/badge/github-white?logo=github&logoColor=black\"></a>\n</div>\n\n<h2>系统需求</h2>\n<ul>\n<li>Python版本 3.10+</li>\n<li>支持CUDA的GPU</li>\n<li>未量化的多模态语言模型需要20GB以上的显存。<ul>\n<li>使用int4量化版本的语言模型可以在不到10GB现存的显卡上运行，但可能会因为量化而影响效果。</li>\n</ul>\n</li>\n<li>数字人部分使用CPU进行推理，测试设备CPU为i9-13980HX，可以达到30FPS.</li>\n</ul>\n<h2>性能</h2>\n<p>我们在测试PC上记录了回答的延迟时间，10次平均时间约为2.2秒，测试PC使用i9-13900KF和Nvidia RTX 4090。延迟从人的语音结束到数字人的语音开始计算，其中会包括RTC双向传输数据时间、VAD判停延迟以及整个流程的计算时间。</p>\n<h2>组件依赖</h2>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>开源项目</th>\n<th>Github地址</th>\n<th>模型地址</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RTC</td>\n<td>HumanAIGC-Engineering/gradio-webrtc</td>\n<td><a href=\"https://github.com/HumanAIGC-Engineering/gradio-webrtc\"><img src=\"https://img.shields.io/badge/github-white?logo=github&logoColor=black\"/></a></td>\n<td></td>\n</tr>\n<tr>\n<td>VAD</td>\n<td>snakers4/silero-vad</td>\n<td><a href=\"https://github.com/snakers4/silero-vad\"><img src=\"https://img.shields.io/badge/github-white?logo=github&logoColor=black\"/></a></td>\n<td></td>\n</tr>\n<tr>\n<td>LLM</td>\n<td>OpenBMB/MiniCPM-o</td>\n<td><a href=\"https://github.com/OpenBMB/MiniCPM-o\"><img src=\"https://img.shields.io/badge/github-white?logo=github&logoColor=black\"/></a></td>\n<td><a href=\"https://huggingface.co/openbmb/MiniCPM-o-2_6\">🤗</a>&nbsp;&nbsp;<a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6\"><img src=\"./assets/images/modelscope_logo.png\" width=\"20px\"></img></a></td>\n</tr>\n<tr>\n<td>LLM-int4</td>\n<td></td>\n<td></td>\n<td><a href=\"https://huggingface.co/openbmb/MiniCPM-o-2_6-int4\">🤗</a>&nbsp;&nbsp;<a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6-int4\"><img src=\"./assets/images/modelscope_logo.png\" width=\"20px\"></img></a></td>\n</tr>\n<tr>\n<td>Avatar</td>\n<td>HumanAIGC/lite-avatar</td>\n<td><a href=\"https://github.com/HumanAIGC/lite-avatar\"><img src=\"https://img.shields.io/badge/github-white?logo=github&logoColor=black\"/></a></td>\n<td></td>\n</tr>\n</tbody></table>\n<h2>安装</h2>\n<p><strong>注意1：本项目子模块以及依赖模型都需要使用git lfs模块，请确认lfs功能已安装</strong></p>\n<pre><code class=\"language-bash\">sudo apt install git-lfs\ngit lfs install \n</code></pre>\n<p><strong>注意2：本项目通过git子模块方式引用三方库，运行前需要更新子模块</strong></p>\n<pre><code class=\"language-bash\">git submodule update --init --recursive\n</code></pre>\n<h4>下载模型</h4>\n<p>本项目中大部分的模型与资源文件都包含在引入的子模块中了。多模态语言模型任然需要用户自行下载。本项目目前使用MiniCPM-o-2.6作为多模态语言模型为数字人提供对话能力，用户可以按需从<a href=\"https://huggingface.co/openbmb/MiniCPM-o-2_6\">Huggingface</a>或者<a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6\">Modelscope</a>下载相关模型。建议将模型直接下载到 &lt;ProjectRoot&gt;/models/ 默认配置的模型路径指向这里，如果放置与其他位置，需要修改配置文件。scripts目录中有对应模型的下载脚本，可供在linux环境下使用，请在项目根目录下运行脚本：</p>\n<pre><code class=\"language-bash\">scripts/download_MiniCPM-o_2.6.sh\n</code></pre>\n<pre><code class=\"language-bash\">scripts/download_MiniCPM-o_2.6-int4.sh\n</code></pre>\n<p><strong>注意：本项目支持MiniCPM-o-2.6的原始模型以及int4量化版本，但量化版本需要安装专用分支的AutoGPTQ，相关细节请参考官方的<a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-o-2_6-int4\">说明</a></strong></p>\n<h4>准备ssl证书</h4>\n<p>由于本项目使用rtc作为视音频传输的通道，用户如果需要从localhost以为的地方连接服务的话，需要准备ssl证书以开启https，默认配置会读取ssl_certs目录下的localhost.crt和localhost.key，用户可以相应修改配置来使用自己的证书。我们也在scripts目录下提供了生成自签名证书的脚本。需要在项目根目录下运行脚本以使生成的证书被放到默认位置。</p>\n<pre><code class=\"language-bash\">scripts/create_ssl_certs.sh\n</code></pre>\n<h4>运行</h4>\n<p>本项目可以以linux容器方式被启动，或者也可以直接启动</p>\n<ul>\n<li>容器化运行：容器依赖nvidia的容器环境，在准备好支持GPU的docker环境后，运行以下命令即可完成镜像的构建与启动：<pre><code class=\"language-bash\">build_and_run.sh\n</code></pre>\n</li>\n<li>直接运行:<ul>\n<li>安装依赖</li>\n</ul>\n<pre><code class=\"language-bash\">pip install -r requirements.txt\n</code></pre>\n<ul>\n<li>启动程序</li>\n</ul>\n<pre><code class=\"language-bash\">python src/demo.py\n</code></pre>\n</li>\n</ul>\n<h4>配置</h4>\n<p>程序默认启动时，会读取 <strong><project_root>/configs/sample.yaml</strong> 中的配置，用户也可以在启动命令后加上--config参数来选择从其他配置文件启动。</p>\n<pre><code class=\"language-bash\">python src/demo.py --config &lt;配置文件的绝对路径&gt;.yaml\n</code></pre>\n<p>可配置的参数列表：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>log.log_level</td>\n<td>INFO</td>\n<td>程序的日志级别。</td>\n</tr>\n<tr>\n<td>service.host</td>\n<td>0.0.0.0</td>\n<td>Gradio服务的监听地址。</td>\n</tr>\n<tr>\n<td>service.port</td>\n<td>8282</td>\n<td>Gradio服务的监听端口。</td>\n</tr>\n<tr>\n<td>service.cert_file</td>\n<td>ssl_certs/localhost.crt</td>\n<td>SSL证书中的证书文件，如果cert_file和cert_key指向的文件都能正确读取，服务将会使用https。</td>\n</tr>\n<tr>\n<td>service.cert_key</td>\n<td>ssl_certs/localhost.key</td>\n<td>SSL证书中的证书文件，如果cert_file和cert_key指向的文件都能正确读取，服务将会使用https。</td>\n</tr>\n<tr>\n<td>chat_engine.model_root</td>\n<td>models</td>\n<td>模型的根目录。</td>\n</tr>\n<tr>\n<td>chat_engine.handler_configs</td>\n<td>N/A</td>\n<td>由各Handler提供的可配置项。</td>\n</tr>\n</tbody></table>\n<p>目前已实现的Handler提供如下的可配置参数：</p>\n<ul>\n<li>VAD</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SileraVad.speaking_threshold</td>\n<td>0.5</td>\n<td>判定输入音频为语音的阈值。</td>\n</tr>\n<tr>\n<td>SileraVad.start_delay</td>\n<td>2048</td>\n<td>当模型输出概率持续大于阈值超过这个时间后，将起始超过阈值的时刻认定为说话的开始。以音频采样数为单位。</td>\n</tr>\n<tr>\n<td>SileraVad.end_delay</td>\n<td>2048</td>\n<td>当模型输出的概率持续小于阈值超过这个时间后，判定说话内容结束。以音频采样数为单位。</td>\n</tr>\n<tr>\n<td>SileraVad.buffer_look_back</td>\n<td>1024</td>\n<td>当使用较高阈值时，语音的起始部分往往有所残缺，该配置在语音的起始点往前回溯一小段时间，避免丢失语音，以音频采样数为单位。</td>\n</tr>\n<tr>\n<td>SileraVad.speech_padding</td>\n<td>512</td>\n<td>返回的音频会在起始与结束两端加上这个长度的静音音频，已采样数为单位。</td>\n</tr>\n</tbody></table>\n<ul>\n<li>语言模型</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>S2S_MiniCPM.model_name</td>\n<td>MiniCPM-o-2_6</td>\n<td>该参数用于选择使用的语言模型，可选&quot;MiniCPM-o-2_6&quot; 或者 &quot;MiniCPM-o-2_6-int4&quot;，需要确保model目录下实际模型的目录名与此一致。</td>\n</tr>\n<tr>\n<td>S2S_MiniCPM.voice_prompt</td>\n<td></td>\n<td>MiniCPM-o的voice prompt</td>\n</tr>\n<tr>\n<td>S2S_MiniCPM.assistant_prompt</td>\n<td></td>\n<td>MiniCPM-o的assistant prompt</td>\n</tr>\n</tbody></table>\n<ul>\n<li>数字人</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Tts2Face.avatar_name</td>\n<td>sample_data</td>\n<td>数字人数据名，目前项目仅提供了&quot;sample_data&quot;可供选择，敬请期待。</td>\n</tr>\n<tr>\n<td>Tts2Face.fps</td>\n<td>25</td>\n<td>数字人的运行帧率，在性能较好的CPU上，可以设置为30FPS</td>\n</tr>\n<tr>\n<td>Tts2Face.enable_fast_mode</td>\n<td>True</td>\n<td>低延迟模式，打开后可以减低回答的延迟，但在性能不足的情况下，可能会在回答的开始产生语音卡顿。</td>\n</tr>\n</tbody></table>\n<p><strong>注意：所有配置中的路径参数都可以使用绝对路径，或者相对于项目根目录的相对路径。</strong></p>\n<h2></h2>\n<p>如果您觉得我们的项目还有点帮助，辛苦帮我们点个⭐，感谢！\n<img src=\"https://api.star-history.com/svg?repos=HumanAIGC-Engineering/OpenAvatarChat&type=Date\" alt=\"\"></p>\n<h2>贡献者</h2>\n<p><a href=\"https://github.com/lovepope\">程刚</a>\n<a href=\"https://github.com/raidios\">陈涛</a>\n<a href=\"https://github.com/sudowind\">王丰</a>\n<a href=\"https://github.com/bingochaos\">黄斌超</a>\n<a href=\"https://github.com/xhup\">徐辉</a>\n<a href=\"https://github.com/bboygun\">何冠桥</a></p>\n"
  }
]